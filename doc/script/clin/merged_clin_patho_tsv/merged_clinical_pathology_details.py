import pandas as pd

# --- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š ---
clinical_path = '/Users/mmatsuda/Desktop/clinical_from_Project/ALLæœ€çµ‚ç¢ºèª/clin/clinical.cohort.2025-06-19/clinical.tsv'
pathology_path = '/Users/mmatsuda/Desktop/clinical_from_Project/ALLæœ€çµ‚ç¢ºèª/clin/clinical.cohort.2025-06-19/pathology_detail.tsv'
raw_output_path = '/Users/mmatsuda/Desktop/clinical_from_Project/ALLæœ€çµ‚ç¢ºèª/clin/merged_output_raw.tsv'
final_output_path = '/Users/mmatsuda/Desktop/clinical_from_Project/ALLæœ€çµ‚ç¢ºèª/clin/merged_output_clinial.tsv'
duplicate_fields_path = '/Users/mmatsuda/Desktop/clinical_from_Project/ALLæœ€çµ‚ç¢ºèª/clin/duplicate_output.tsv'


# --- å·¥ç¨‹1.ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã™ã¹ã¦æ–‡å­—åˆ—ã¨ã—ã¦ï¼‰ ---
df1 = pd.read_csv(clinical_path, sep='\t', dtype=str, on_bad_lines='skip')
df2 = pd.read_csv(pathology_path, sep='\t', dtype=str, on_bad_lines='skip')

# --- å·¥ç¨‹2.é‡è¤‡åˆ—ã®å‰Šé™¤ï¼ˆcases.case_id ä»¥å¤–ã®å…±é€šåˆ—ã‚’ df2 ã‹ã‚‰å‰Šé™¤ï¼‰ ---
common_cols = [col for col in df1.columns if col in df2.columns and col != 'cases.case_id']
df2 = df2.drop(columns=common_cols)

# --- å·¥ç¨‹3.å†…éƒ¨çµåˆ ---
df_merged = pd.merge(df1, df2, on='cases.case_id', how='inner')

# --- å·¥ç¨‹4.çµåˆç›´å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ ---
df_merged.to_csv(raw_output_path, sep='\t', index=False)

# --- å·¥ç¨‹5.é‡è¤‡ã‚’è€ƒæ…®ã—ãŸåˆ—åå¤‰æ›é–¢æ•° ---
def transform_column_name(col, duplicates_map):
    if '.' in col:
        prefix, rest = col.split('.', 1)
        simple_name = f"clin_{rest}"
        if simple_name in duplicates_map:
            return f"clin_{prefix}_{rest}"  # é‡è¤‡ãŒã‚ã‚‹å ´åˆã¯ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’æ®‹ã™
        else:
            return simple_name
    else:
        return col

# --- å·¥ç¨‹6.é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®æ¤œå‡ºã¨å ±å‘Šç”¨æ•´å½¢ ---

prefix_map = {}
for col in df_merged.columns:
    if '.' in col:
        prefix, rest = col.split('.', 1)
        transformed = f"clin_{rest}"
        report_name = f"clin_{prefix}_{rest}"
        if transformed in prefix_map:
            prefix_map[transformed].append(report_name)
        else:
            prefix_map[transformed] = [report_name]

duplicates = {k: v for k, v in prefix_map.items() if len(v) > 1}

transformed_names = [transform_column_name(col, duplicates) for col in df_merged.columns]

# --- å·¥ç¨‹7.é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ä¿å­˜ ---
with open(duplicate_fields_path, 'w') as f:
    f.write("Fields that would be duplicated after replacing prefix with 'clin_':\n")
    for name, sources in duplicates.items():
        f.write(f"{name}: " + ", ".join(sources) + "\n")

# --- å·¥ç¨‹8.åˆ—åã®æ›´æ–° ---
df_merged.columns = transformed_names

# --- å·¥ç¨‹9. '--' ã‚„ \"'--\" ã‚’ç©ºæ–‡å­—ã«ç½®æ› ---
df_merged.replace({"--": "", "'--": ""}, inplace=True)

# --- å·¥ç¨‹10.ãƒ¦ãƒ‹ãƒ¼ã‚¯IDåˆ—ã®è¿½åŠ  ---
case_id_col = "clin_case_id"
treatment_col = "clin_treatment_type"
treatment_map = {
    "Pharmaceutical Therapy, NOS": "Phar",
    "Radiation Therapy, NOS": "Radi"
}

def create_unique_id(row):
    treatment = treatment_map.get(row.get(treatment_col, ''), row.get(treatment_col, ''))
    return f"{row.get(case_id_col, '')}__{treatment}"

df_merged["clin_case_id___hoge"] = df_merged.apply(create_unique_id, axis=1)

# --- å·¥ç¨‹11.å‡ºåŠ› ---
df_merged.to_csv(final_output_path, sep='\t', index=False)
print(f"âœ… Done. {len(df_merged.columns)} fields processed, columns renamed, '--' replaced, and unique ID column appended.")
print(f"ğŸ“ Duplicate fields (after renaming) saved to: {duplicate_fields_path}")
